<h1> What is - Logic Regression #2 </h1>

<p>
  $$ h(x) = \theta_0 + \theta_1 x $$
  $$ h_{\theta}(x) = \theta_0 + \theta_1 x $$
  $$ h_{\theta}(x) = \theta_0 + \theta_1 x + \theta_2 x + \theta_3 x$$
  $$ h_{\theta}(x) = \theta_0 + \theta_1 x + \theta_2 x + \theta_3 x + ... + \theta_n x$$
  $$ h_{\theta}(x) = \theta^T X$$
θ was a matrix [n + 1 行， 1列], θ<sup>T</sup>  was a matrix [1 行， n+1列]; X是属性值(features), 为 n行、1列的matrix。
它们做矩阵相乘的结果，就是一个1乘1的矩阵。
</br>
For classification hypothesis representation we do hθ(x) = g((θT x))
$$ h_{\theta}(x) = g(\theta^T X)$$

</p>
